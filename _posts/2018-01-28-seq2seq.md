---
layout: post
title: Sequence to Sequence
tags: stats/maths
category: ml
summary: ""
img_post: 20180225-auroc.jpg
github-link: na
---



<script src="/js/plotly-latest.min.js"></script>

<script type="text/javascript"
   src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>



The aim is to convert a sequence into a fixed size feature vector that encode only the important information of the sequence.
The entire input is passed to a LSTM the encode. It returns the internal state context/state

{% tikz 2 %}
  \node (bx1) at (0,0) [draw,thick,minimum width=5cm,minimum height=2cm] {};
  \node[align=center,font=\large,rotate=0] at (bx1.center) {encoder};

  \node (bx2) at (9,0) [draw,thick,minimum width=5cm,minimum height=2cm] {};
  \node[align=center,font=\large,rotate=0] at (bx2.center) {Decoder};

  \draw [->,>=stealth] (2.5,0.3) -- node[pos=.7,fill=white,inner sep=0pt]{context c}(6.5,0.3);
  \draw [->,>=stealth] (2.5,-0.3) -- node[pos=.7,fill=white,inner sep=0pt]{h}(6.5,-0.3);
  
{% endtikz %}
The state will serve as the context/conditioning of the decoder. The other RNN (the decoder) is trained to predict the element/target of the next step . The input to the decoder is the $$h$$ and $$c$$ of the last step of the encoder.